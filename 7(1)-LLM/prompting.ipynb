{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53cd899e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in /opt/anaconda3/lib/python3.13/site-packages (0.30.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.13/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (2.3.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.13/site-packages (4.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from groq) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.13/site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.13/site-packages (from groq) (2.10.5)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.13/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /opt/anaconda3/lib/python3.13/site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.13/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->groq) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.34.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.18.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (1.26.20)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install groq python-dotenv numpy tqdm datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "249253df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "load_dotenv()\n",
    "random.seed(0)\n",
    "\n",
    "client = Groq()\n",
    "gsm8k_dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "\n",
    "gsm8k_train = gsm8k_dataset[\"train\"]\n",
    "gsm8k_test  = gsm8k_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4d75bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_using_Llama(\n",
    "        prompt: str,\n",
    "        model: str = \"llama3-8b-8192\"\n",
    "    ):\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant that solves math problems.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            model=model,\n",
    "            temperature=0.3, ### 수정해도 됩니다!\n",
    "            stream=False\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API call error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef65ad3",
   "metadata": {},
   "source": [
    "#### 응답 잘 나오는지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a37fad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm excited to help you with your math problems. What kind of math do you need help with? Do you have a specific problem you're stuck on or a concept you're struggling with? Let me know and I'll do my best to assist you!\n"
     ]
    }
   ],
   "source": [
    "response = generate_response_using_Llama(\n",
    "    prompt=\"Hello world!\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988803ae",
   "metadata": {},
   "source": [
    "#### GSM8K 데이터셋 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbd177eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question]\n",
      "Janet’s ducks lay 16 eggs per day\n",
      " She eats three for breakfast every morning and bakes muffins for her friends every day with four\n",
      " She sells the remainder at the farmers' market daily for $2 per fresh duck egg\n",
      " How much in dollars does she make every day at the farmers' market?\n",
      "====================================================================================================\n",
      "[Answer]\n",
      "Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
      "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\n",
      "#### 18\n"
     ]
    }
   ],
   "source": [
    "print(\"[Question]\")\n",
    "for l in gsm8k_test['question'][0].split(\".\"):\n",
    "    print(l)\n",
    "print(\"=\"*100)\n",
    "print(\"[Answer]\")\n",
    "print(gsm8k_test['answer'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaabe66c",
   "metadata": {},
   "source": [
    "#### Util 함수들\n",
    "- extract_final_answer: LLM의 응답을 parse하여 최종 결과만 추출 (정답과 비교하기 위해)\n",
    "- run_benchmark_test: 벤치마크 테스트\n",
    "- save_final_result: 결과물 제출을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40c10811",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 수정해도 됩니다!\n",
    "def extract_final_answer(response: str):\n",
    "    regex = r\"(?:Answer:|Model response:)\\s*\\$?([0-9,]+)\\b|([0-9,]+)\\s*(meters|cups|miles|minutes)\"\n",
    "    matches = re.finditer(regex, response, re.MULTILINE)\n",
    "    results = [match.group(1) if match.group(1) else match.group(2).replace(\",\", \"\") for match in matches]\n",
    "\n",
    "    if len(results) == 0:\n",
    "        additional_regex = r\"\\$?([0-9,]+)\"\n",
    "        additional_matches = re.finditer(additional_regex, response, re.MULTILINE)\n",
    "        results.extend([match.group(1).replace(\",\", \"\") for match in additional_matches])\n",
    "\n",
    "    return results[-1] if results else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e3a05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 수정해도 됩니다!\n",
    "def run_benchmark_test(\n",
    "        dataset,\n",
    "        prompt: str,\n",
    "        model: str = \"llama3-8b-8192\",\n",
    "        num_samples: int = 50,\n",
    "        VERBOSE: bool = False\n",
    "    ):\n",
    "    correct = 0\n",
    "    total   = 0\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(min(num_samples, len(dataset)))):\n",
    "        question = dataset[i][\"question\"]\n",
    "        correct_answer = float(re.findall(r'\\d+(?:\\.\\d+)?', dataset[i][\"answer\"].split('####')[-1])[0])\n",
    "\n",
    "        response = generate_response_using_Llama(\n",
    "            prompt=prompt.format(question=question),\n",
    "            model=model\n",
    "        )\n",
    "\n",
    "        if response:\n",
    "            if VERBOSE:\n",
    "                print(\"=\"*50)\n",
    "                print(response)\n",
    "                print(\"=\"*50)\n",
    "            predicted_answer = extract_final_answer(response)\n",
    "\n",
    "            if isinstance(predicted_answer, str):\n",
    "                if predicted_answer.strip() == \"\":\n",
    "                    predicted_answer = None\n",
    "                else:\n",
    "                    try:\n",
    "                        predicted_answer = float(predicted_answer.replace(\",\", \"\"))\n",
    "                    except ValueError:\n",
    "                        predicted_answer = None\n",
    "                    if predicted_answer is not None:\n",
    "                        diff = abs(predicted_answer - correct_answer)\n",
    "                        is_correct = diff < 1e-5\n",
    "                    else:\n",
    "                        is_correct = False\n",
    "                                \n",
    "            is_correct = diff < 1e-5 if predicted_answer is not None else False\n",
    "            \n",
    "            if is_correct:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "            results.append({\n",
    "                'question': question,\n",
    "                'correct_answer': correct_answer,\n",
    "                'predicted_answer': predicted_answer,\n",
    "                'response': response,\n",
    "                'correct': is_correct\n",
    "            })\n",
    "\n",
    "            if (i + 1) % 5 == 0:\n",
    "                current_acc = correct/total if total > 0 else 0\n",
    "                print(f\"Progress: [{i+1}/{num_samples}]\")\n",
    "                print(f\"Current Acc.: [{current_acc:.2%}]\")\n",
    "\n",
    "    return results, correct/total if total > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e63f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_final_result(results: List[Dict[str, Any]], accuracy: float, filename: str) -> None:\n",
    "    result_str = f\"====== ACCURACY: {accuracy} ======\\n\\n\"\n",
    "    result_str += f\"[Details]\\n\"\n",
    "    \n",
    "    for idx, result in enumerate(results):\n",
    "        result_str += f\"Question {idx+1}: {result['question']}\\n\"\n",
    "        result_str += f\"Correct Answer: {result['correct_answer']}\\n\"\n",
    "        result_str += f\"Predicted Answer: {result['predicted_answer']}\\n\"\n",
    "        result_str += f\"Correct: {result['correct']}\\n\\n\"\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(result_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498f9ed",
   "metadata": {},
   "source": [
    "#### Direct prompting with few-shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f430083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_direct_prompt(num_examples: int = 3) -> str:\n",
    "    train_dataset = gsm8k_train\n",
    "\n",
    "    sampled_indices = random.sample(\n",
    "        [i for i in range(len(train_dataset['question']))],\n",
    "        num_examples\n",
    "    )\n",
    "\n",
    "    prompt = \"Instruction:\\nSolve the following mathematical question and generate ONLY the answer after a tag, 'Answer:' without any rationale.\\n\"\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        cur_question = train_dataset['question'][i]\n",
    "        cur_answer = train_dataset['answer'][i].split(\"####\")[-1].strip()\n",
    "\n",
    "        prompt += f\"\\n[Example {i+1}]\\n\"\n",
    "        prompt += f\"Question:\\n{cur_question}\\n\"\n",
    "        prompt += f\"Answer:{cur_answer}\\n\"\n",
    "\n",
    "    prompt += \"\\nQuestion:\\n{question}\\nAnswer:\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68a2b484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:03<00:03,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/10]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/10]\n",
      "Current Acc.: [30.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### 어떤 방식으로 저장되는지 확인해보세요!\n",
    "PROMPT = construct_direct_prompt(3)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt=PROMPT,\n",
    "    VERBOSE=VERBOSE,\n",
    "    num_samples=10\n",
    ")\n",
    "save_final_result(results, accuracy, \"example.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41874896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:02<00:24,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:05<00:21,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [10.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:07<00:19,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [6.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:12<00:35,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [15.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:26<01:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [16.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:39<00:53,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:53<00:41,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [17.14%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:07<00:27,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [15.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [01:20<00:13,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [15.56%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:34<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [18.00%]\n",
      "0 shot completed with 18.00% accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:13<02:03,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:27<01:48,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [30.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:40<01:35,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:54<01:22,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [25.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [01:08<01:08,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [24.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [01:21<00:54,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [23.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:35<00:41,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:49<00:29,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [17.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [02:01<00:13,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [17.78%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:15<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [20.00%]\n",
      "3 shot completed with 20.00% accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:13<02:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [40.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:27<01:52,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:40<01:31,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [13.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:53<01:18,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [15.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [01:06<01:04,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [01:19<00:52,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [23.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:32<00:38,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:45<00:25,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [17.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [01:57<00:12,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [15.56%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:12<00:00,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [18.00%]\n",
      "5 shot completed with 18.00% accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: 0 shot, 3 shot, 5 shot direct prompting을 통해 벤치마크 테스트를 한 후, 각각 direct_prompting_{shot: int}.txt로 저장해주세요!\n",
    "# 예시: shot이 5인 경우 direct_prompting_5.txt\n",
    "# 항상 num_samples=50 입니다!\n",
    "\n",
    "for shot in [0, 3, 5]:\n",
    "    PROMPT = construct_direct_prompt(shot)\n",
    "    results, accuracy = run_benchmark_test(\n",
    "        dataset=gsm8k_test,\n",
    "        prompt=PROMPT,\n",
    "        VERBOSE=VERBOSE,\n",
    "        num_samples=50\n",
    "    )\n",
    "    save_final_result(results, accuracy, f\"direct_prompting_{shot}.txt\")\n",
    "    print(f\"{shot} shot completed with {accuracy:.2%} accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd21d1",
   "metadata": {},
   "source": [
    "### Chain-of-Thought prompting with few-shot example\n",
    "```text\n",
    "[Question]\n",
    "Janet’s ducks lay 16 eggs per day\n",
    " She eats three for breakfast every morning and bakes muffins for her friends every day with four\n",
    " She sells the remainder at the farmers' market daily for $2 per fresh duck egg\n",
    " How much in dollars does she make every day at the farmers' market?\n",
    "====================================================================================================\n",
    "[Answer]\n",
    "Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
    "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\n",
    "#### 18\n",
    "```\n",
    "\n",
    "[Answer] 아래의 정답을 도출하는 과정을 예시로 달아주면 CoT의 few shot이 되겠죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73a989e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_CoT_prompt(num_examples: int = 3) -> str:\n",
    "    \"\"\"CoT 프롬프트를 구성하는 함수\"\"\"\n",
    "    train_dataset = gsm8k_train\n",
    "    \n",
    "    if num_examples > len(train_dataset):\n",
    "        num_examples = len(train_dataset)\n",
    "\n",
    "    sampled_indices = random.sample(\n",
    "        range(len(train_dataset)),\n",
    "        num_examples\n",
    "    )\n",
    "    \n",
    "    prompt = (\"Instruction:\\n\" \n",
    "              \"Solve the following mathematical question. Provide a step-by-step rationale for your answer, \" \n",
    "              \"and then provide the final answer in the format '#### <answer>'.\\n\")\n",
    "\n",
    "    for i, idx in enumerate(sampled_indices):\n",
    "        cur_question = train_dataset['question'][idx]\n",
    "        cur_answer = train_dataset['answer'][idx]\n",
    "\n",
    "        prompt += f\"\\n[Example {i+1}]\\n\"\n",
    "        prompt += f\"Question:\\n{cur_question}\\n\"\n",
    "        prompt += f\"Answer:\\n{cur_answer}\\n\"\n",
    "\n",
    "    prompt += \"\\nQuestion:\\n{question}\\nAnswer:\"\n",
    "    \n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c510586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:13<01:59,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:32<02:20,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:51<02:17,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [66.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [01:10<01:47,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [01:26<01:15,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [64.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [01:41<00:57,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [63.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:58<00:47,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [68.57%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [02:15<00:33,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [65.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [02:32<00:17,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [64.44%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [62.00%]\n",
      "0 shot completed with 62.00% accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:39<06:03,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [01:23<05:54,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [02:09<05:22,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [02:52<04:25,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [65.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [03:39<03:36,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [64.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [04:23<02:55,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [66.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [05:03<02:02,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [71.43%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [05:45<01:26,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [65.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [06:28<00:43,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [66.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:14<00:00,  8.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [68.00%]\n",
      "3 shot completed with 68.00% accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [01:02<09:25, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [02:07<08:43, 13.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [03:17<08:17, 14.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [04:22<06:30, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [75.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [05:29<05:21, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [72.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [06:34<04:21, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [73.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [07:37<03:11, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [77.14%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [08:41<02:08, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [75.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [09:46<01:04, 12.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [75.56%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:51<00:00, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [74.00%]\n",
      "5 shot completed with 74.00% accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: 0 shot, 3 shot, 5 shot CoT prompting을 통해 벤치마크 테스트를 한 후, 각각 CoT_prompting_{shot: int}.txt로 저장해주세요!\n",
    "# 예시: shot이 5인 경우 CoT_prompting_5.txt\n",
    "# 항상 num_samples=50 입니다!\n",
    "\n",
    "for shot in [0, 3, 5]:\n",
    "    PROMPT = construct_CoT_prompt(shot)\n",
    "    results, accuracy = run_benchmark_test(\n",
    "        dataset=gsm8k_test,\n",
    "        prompt=PROMPT,\n",
    "        VERBOSE=VERBOSE,\n",
    "        num_samples=50\n",
    "    )\n",
    "    save_final_result(results, accuracy, f\"CoT_prompting_{shot}.txt\")\n",
    "    print(f\"{shot} shot completed with {accuracy:.2%} accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c45b54",
   "metadata": {},
   "source": [
    "### Construct your prompt!!\n",
    "\n",
    "목표: 본인만의 프롬프트를 통해 정답률을 더 끌어올려보기!\n",
    "- gsm8k의 train 데이터셋에서 예시를 가져온 다음 (자유롭게!)\n",
    "- 그 예시들에 대한 풀이 과정을 만들어주세요!\n",
    "- 모든 것들이 자유입니다! Direct Prompting, CoT Prompting을 한 결과보다 정답률만 높으면 돼요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "09062c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_list = [\n",
    "    \"\"\"Question:\n",
    "A bag has 5 red balls and 3 blue balls. If you take out 2 red balls, how many red balls remain?\n",
    "Scratchpad:\n",
    "Start with 5 red balls.\n",
    "Take out 2 → 5 - 2 = 3 red balls left.\n",
    "Answer: 3\"\"\",\n",
    "\n",
    "    \"\"\"Question:\n",
    "A car travels 60 km in 1.5 hours. What is its average speed in km/h?\n",
    "Scratchpad:\n",
    "Distance = 60 km, Time = 1.5 h\n",
    "Speed = Distance / Time = 60 / 1.5 = 40 km/h\n",
    "Answer: 40\"\"\",\n",
    "\n",
    "    \"\"\"Question:\n",
    "A store offers a 25% discount on a $200 item. What is the final price?\n",
    "Scratchpad:\n",
    "Discount = 25% of 200 = 0.25 × 200 = 50\n",
    "Final price = 200 - 50 = 150\n",
    "Answer: 150\"\"\"\n",
    "]\n",
    "\n",
    "from typing import List\n",
    "import re\n",
    "import time\n",
    "\n",
    "# -------------------------\n",
    "# 1. Scratchpad Prompt 생성\n",
    "# -------------------------\n",
    "def construct_my_prompt(example_list: List[str], num_examples: int = 3):\n",
    "    prompt = (\n",
    "        \"Instruction:\\n\"\n",
    "        \"You are a careful math tutor. Solve each math problem step-by-step.\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"1. Restate the problem briefly.\\n\"\n",
    "        \"2. List all known values.\\n\"\n",
    "        \"3. Show every calculation step explicitly.\\n\"\n",
    "        \"4. Keep intermediate numbers consistent.\\n\"\n",
    "        \"5. At the end, write ONLY the final number after 'Answer:'. No units, no extra words.\\n\"\n",
    "    )\n",
    "    \n",
    "    for i, example in enumerate(example_list[:num_examples]):\n",
    "        prompt += f\"\\n[Example {i+1}]\\n{example.strip()}\\n\"\n",
    "\n",
    "    prompt += \"\\nQuestion:\\n{question}\\nScratchpad:\\nAnswer:\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 2. 답 추출 개선\n",
    "# -------------------------\n",
    "def extract_answer(text: str) -> str:\n",
    "    # 'Answer:' 또는 'Correct Answer:' 뒤의 숫자를 우선 추출\n",
    "    match = re.search(r\"(?:Answer|Correct Answer)\\s*[:\\-]?\\s*(-?\\d+(?:\\.\\d+)?)\", text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    # 없으면 마지막 숫자를 추출\n",
    "    matches = re.findall(r\"-?\\d+(?:\\.\\d+)?\", text)\n",
    "    return matches[-1] if matches else \"N/A\"\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3. 실행 함수 (강화된 검증)\n",
    "# -------------------------\n",
    "def run_with_answer_verification(prompt_template, dataset, num_samples=10):\n",
    "    results = []\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        q = dataset['question'][i]\n",
    "        gt = dataset['answer'][i].split(\"####\")[-1].strip()\n",
    "\n",
    "        # 1차 추론\n",
    "        reasoning_prompt = prompt_template.format(question=q)\n",
    "        reasoning_output = generate_response_using_Llama(reasoning_prompt)\n",
    "\n",
    "        # 2차 검증 - 무조건 새로 풀기\n",
    "        verification_prompt = (\n",
    "            \"Instruction:\\n\"\n",
    "            \"The following math problem was solved, but the answer might be wrong.\\n\"\n",
    "            \"Ignore the previous solution completely. Solve from scratch.\\n\"\n",
    "            \"Follow the same rules:\\n\"\n",
    "            \" - Restate briefly, list values, calculate step-by-step.\\n\"\n",
    "            \" - End with ONLY the number after 'Correct Answer:'.\\n\\n\"\n",
    "            f\"Original Question:\\n{q}\\n\\n\"\n",
    "            \"Correct Answer:\"\n",
    "        )\n",
    "        verification_output = generate_response_using_Llama(verification_prompt)\n",
    "\n",
    "        # 최종 답 추출\n",
    "        verified_answer = extract_answer(verification_output)\n",
    "\n",
    "        try:\n",
    "            is_correct = abs(float(verified_answer) - float(gt)) < 1e-3\n",
    "        except:\n",
    "            is_correct = False\n",
    "\n",
    "        correct += is_correct\n",
    "\n",
    "        results.append({\n",
    "            \"question\": q,\n",
    "            \"correct_answer\": gt,\n",
    "            \"predicted_answer\": verified_answer,\n",
    "            \"correct\": is_correct\n",
    "        })\n",
    "\n",
    "        if (i + 1) % 5 == 0:\n",
    "            current_acc = correct / (i + 1)\n",
    "            print(f\"Progress: [{i+1}/{num_samples}] | Current Acc.: {current_acc:.2%}\")\n",
    "\n",
    "    accuracy = correct / num_samples\n",
    "    return results, accuracy\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 프롬프트 만들기\n",
    "# -------------------------\n",
    "prompt_template = construct_my_prompt(example_list, num_examples=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ac2b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:11<02:06,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500231, Requested 147. Please try again in 1m5.489999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500230, Requested 166. Please try again in 1m8.6002s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:12<00:51,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500230, Requested 151. Please try again in 1m5.845199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500229, Requested 239. Please try again in 1m20.8916s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:12<00:26,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500227, Requested 172. Please try again in 1m9.109s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500226, Requested 168. Please try again in 1m8.242799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:12<00:15,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500226, Requested 193. Please try again in 1m12.4148s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500225, Requested 222. Please try again in 1m17.271s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:12<00:12,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500224, Requested 177. Please try again in 1m9.328s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:13<00:11,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500221, Requested 188. Please try again in 1m10.7618s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500220, Requested 181. Please try again in 1m9.3852s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:13<00:09,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500219, Requested 185. Please try again in 1m9.9204s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:14<00:08,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500218, Requested 180. Please try again in 1m8.8064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500217, Requested 176. Please try again in 1m7.947199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:14<00:06,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500216, Requested 220. Please try again in 1m15.3774s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500215, Requested 176. Please try again in 1m7.6022s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:14<00:05,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500214, Requested 168. Please try again in 1m6.062799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500213, Requested 147. Please try again in 1m2.249s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:15<00:05,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500212, Requested 185. Please try again in 1m8.660399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500211, Requested 181. Please try again in 1m7.7962s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:15<00:04,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500210, Requested 165. Please try again in 1m4.8724s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500209, Requested 173. Please try again in 1m6.0868s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:15<00:04,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500208, Requested 156. Please try again in 1m2.9862s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500207, Requested 158. Please try again in 1m3.1458s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:16<00:03,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500206, Requested 178. Please try again in 1m6.4128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500205, Requested 178. Please try again in 1m6.2578s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [00:16<00:03,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500204, Requested 173. Please try again in 1m5.233799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500203, Requested 172. Please try again in 1m4.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:16<00:03,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500202, Requested 199. Please try again in 1m9.3986s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500201, Requested 151. Please try again in 1m0.9442s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:17<00:02,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500200, Requested 180. Please try again in 1m5.7864s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500199, Requested 160. Please try again in 1m2.1674s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:17<00:02,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500198, Requested 149. Please try again in 1m0.0986s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500197, Requested 159. Please try again in 1m1.6666s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [00:17<00:02,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500196, Requested 164. Please try again in 1m2.363599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01k1r7amteerjtz9y66485vm8m` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 500196, Requested 153. Please try again in 1m0.3088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [00:17<00:06,  2.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shot \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m]:\n\u001b[1;32m      6\u001b[0m     PROMPT \u001b[38;5;241m=\u001b[39m construct_my_prompt(gsm8k_train, num_examples\u001b[38;5;241m=\u001b[39mshot)\n\u001b[0;32m----> 7\u001b[0m     results, accuracy \u001b[38;5;241m=\u001b[39m run_benchmark_test(\n\u001b[1;32m      8\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mgsm8k_test,\n\u001b[1;32m      9\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mPROMPT,\n\u001b[1;32m     10\u001b[0m         VERBOSE\u001b[38;5;241m=\u001b[39mVERBOSE,\n\u001b[1;32m     11\u001b[0m         num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m     save_final_result(results, accuracy, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMy_prompting_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m shot completed with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[30], line 17\u001b[0m, in \u001b[0;36mrun_benchmark_test\u001b[0;34m(dataset, prompt, model, num_samples, VERBOSE)\u001b[0m\n\u001b[1;32m     14\u001b[0m question \u001b[38;5;241m=\u001b[39m dataset[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m correct_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+(?:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)?\u001b[39m\u001b[38;5;124m'\u001b[39m, dataset[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m####\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 17\u001b[0m response \u001b[38;5;241m=\u001b[39m generate_response_using_Llama(\n\u001b[1;32m     18\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt\u001b[38;5;241m.\u001b[39mformat(question\u001b[38;5;241m=\u001b[39mquestion),\n\u001b[1;32m     19\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m VERBOSE:\n",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m, in \u001b[0;36mgenerate_response_using_Llama\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_response_using_Llama\u001b[39m(\n\u001b[1;32m      2\u001b[0m         prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m      3\u001b[0m         model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3-8b-8192\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     ):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m         chat_completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      7\u001b[0m             messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      8\u001b[0m                 {\n\u001b[1;32m      9\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant that solves math problems.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m                 },\n\u001b[1;32m     12\u001b[0m                 {\n\u001b[1;32m     13\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     14\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt\n\u001b[1;32m     15\u001b[0m                 }\n\u001b[1;32m     16\u001b[0m             ],\n\u001b[1;32m     17\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     18\u001b[0m             temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;66;03m### 수정해도 됩니다!\u001b[39;00m\n\u001b[1;32m     19\u001b[0m             stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         )\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m chat_completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/groq/resources/chat/completions.py:368\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    230\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    231\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/openai/v1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    370\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    371\u001b[0m             {\n\u001b[1;32m    372\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    373\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    374\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexclude_domains\u001b[39m\u001b[38;5;124m\"\u001b[39m: exclude_domains,\n\u001b[1;32m    375\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    376\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m    377\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m    378\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_domains\u001b[39m\u001b[38;5;124m\"\u001b[39m: include_domains,\n\u001b[1;32m    379\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    380\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m    381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m    385\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m    386\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    387\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_format,\n\u001b[1;32m    389\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    390\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_settings\u001b[39m\u001b[38;5;124m\"\u001b[39m: search_settings,\n\u001b[1;32m    391\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m    392\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m    393\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m    394\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m    395\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    396\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    397\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m    398\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    399\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m    400\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    401\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m    402\u001b[0m             },\n\u001b[1;32m    403\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    404\u001b[0m         ),\n\u001b[1;32m    405\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    406\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    407\u001b[0m         ),\n\u001b[1;32m    408\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m    409\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    410\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    411\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/groq/_base_client.py:1232\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1220\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1228\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1229\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1230\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1231\u001b[0m     )\n\u001b[0;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/groq/_base_client.py:970\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    968\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 970\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m    971\u001b[0m         request,\n\u001b[1;32m    972\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[1;32m    973\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    976\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[1;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    219\u001b[0m     )\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/ssl.py:1285\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1284\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/ssl.py:1140\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: 만든 0 shot, 3 shot, 5 shot example과 프롬프트를 통해 벤치마크 테스트를 한 후, 각각 My_prompting_{shot: int}.txt로 저장해주세요!\n",
    "# 예시: shot이 5인 경우 My_prompting_5.txt\n",
    "# 항상 num_samples=50 입니다!\n",
    "\n",
    "for shot in [0, 3, 5]:\n",
    "    PROMPT = construct_my_prompt(gsm8k_train, num_examples=shot)\n",
    "    results, accuracy = run_benchmark_test(\n",
    "        dataset=gsm8k_test,\n",
    "        prompt=PROMPT,\n",
    "        VERBOSE=VERBOSE,\n",
    "        num_samples=50\n",
    "    )\n",
    "    save_final_result(results, accuracy, f\"My_prompting_{shot}.txt\")\n",
    "    print(f\"{shot} shot completed with {accuracy:.2%} accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd837d7",
   "metadata": {},
   "source": [
    "### 보고서 작성하기\n",
    "#### 아래의 내용이 포함되면 됩니다!\n",
    "\n",
    "1. Direct Prompting, CoT Prompting, My Prompting을 0 shot, 3 shot, 5 shot 정답률을 표로 보여주세요!\n",
    "2. CoT Prompting이 Direct Prompting에 비해 왜 좋을 수 있는지에 대해서 서술해주세요!\n",
    "3. 본인이 작성한 프롬프트 기법이 CoT에 비해서 왜 더 좋을 수 있는지에 대해서 설명해주세요!\n",
    "4. 최종적으로, `PROMPTING.md`에 보고서를 작성해주세요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
